{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "title: Spatial Interaction with Spatial Dependence\n",
    "jupyter: conda-env-nersa25-py\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "from formulaic import Formula\n",
    "from geosnap import DataStore\n",
    "from geosnap import io as gio\n",
    "from libpysal.graph import Graph\n",
    "from shapely import LineString\n",
    "from spreg import GMM_Error, GM_Lag\n",
    "%load_ext watermark\n",
    "%watermark -a 'eli knaap'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if our flows are not independent?\n",
    "\n",
    "Like any regression, a critical assumption in spatial interaction models\n",
    "is that observations are *independent* from one another. And like any model\n",
    "using spatial data, the model is misspecified if residuals are spatially\n",
    "autocorrelated (indicating the input data fail the independence criterion). We\n",
    "can use spatial econometric approaches to handle this situation, albeit with\n",
    "some minor modifications because\n",
    "\n",
    "- autocorrelation may come from origins, destinations, or both\n",
    "- we need to approximate the data using a log-linear model instead of proper Poisson\n",
    "\n",
    "Approaches for estimating spatial lag models are described in\n",
    "@lesage2007KnowledgeSpillovers and @lesage2008SpatialEconometric while error\n",
    "models are described by @fischer2008ModelingSpatial, the latter two of which use\n",
    "conventional estimation techniques with specialized $W$ matrices based on the\n",
    "notion of neighboring origins or neighboring destinations. We explore how to\n",
    "conduct these analyses below. For further background, consult\n",
    "@fischer2008ModelingSpatial, @lesage2007KnowledgeSpillovers,\n",
    "@lesage2008SpatialEconometric, @lesage2010SpatialEconometric,\n",
    "@lesage2013SpatialInteraction, @lesage2014WhatRegional,\n",
    "@thomas-agnan2014SpatialEconometric, @griffith2017SpatialAutocorrelation and\n",
    "@ord1975EstimationMethods.\n",
    "\n",
    "## Spatial Econometric Models\n",
    "\n",
    "In the following example we will focus on the spatial interaction specification\n",
    "of two workhorse models in spatial econometrics: the \"spatial lag\" and \"spatial\n",
    "error\" models. Following the log-linear specification from the prior section,\n",
    "these are given by\n",
    "\n",
    "### Spatial Lag\n",
    "\n",
    "$$ \\log(F_{ij} + \n",
    "\\delta) =  \\log(\\kappa) + \\rho W\\log(F_{ij}+\\delta) + \\alpha \\log(O_i)  + \\beta \\log(D_j) + \\gamma d_{ij} + \\epsilon_{ij} $$ {#eq-interaction-spatlag}\n",
    "\n",
    "### Spatial Error\n",
    "\n",
    "$$\n",
    "\\begin{gathered}\n",
    "\\log(F_{ij} + \n",
    "\\delta) = \\log(\\kappa) +  \\alpha \\log(O_i)  + \\beta \\log(D_j) + \\gamma d_{ij} + u \\\\\n",
    "u = \\lambda Wu +\\epsilon_{ij}\n",
    "\\end{gathered}\n",
    "$$  {#eq-interaction-spaterr}\n",
    "\n",
    "\n",
    "Note there's a sizeable and growing literature focused on the appropriateness of\n",
    "different estimation techniques for count-based models, particularly in the\n",
    "gravity model context\n",
    "[@manning2001EstimatingLog; @santossilva2010ExistenceMaximum; @santossilva2011FurtherSimulation; @silva2006LogGravity].\n",
    "For the purpose of this workshop it's sufficient to say that log-linear models\n",
    "induce a certain level of bias--and it's important to be aware. However flow\n",
    "models also display empirical residual autocorrelation, so nonlinear but\n",
    "nonspatial models *also* induce bias (and it's hard to estimate nonlinear\n",
    "spatial models). So here we accept one bias in favor of the other for the sake\n",
    "of demonstration and concern for spatial effects. Consult the literature for a\n",
    "deeper dive.\n",
    "\n",
    "## Data Preparation\n",
    "\n",
    "We will follow the same data processing steps as in the previous sections,\n",
    "collecting data for Washington D.C. and converting it into a Graph of flows,\n",
    "then merging with additional data from the Census."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = DataStore()\n",
    "\n",
    "dc = gio.get_acs(datasets, state_fips=\"11\", years=2021, level=\"tract\")\n",
    "\n",
    "dc_flows = pd.read_csv(\n",
    "    \"https://lehd.ces.census.gov/data/lodes/LODES8/dc/od/dc_od_main_JT00_2022.csv.gz\",\n",
    "    converters={\"w_geocode\": str, \"h_geocode\": str},\n",
    "    low_memory=False,\n",
    "    encoding=\"latin1\",\n",
    ")\n",
    "dc_flows[\"w_tr_geocode\"] = dc_flows[\"w_geocode\"].str[:11]\n",
    "dc_flows[\"h_tr_geocode\"] = dc_flows[\"h_geocode\"].str[:11]\n",
    "dc_flows = dc_flows[[\"w_geocode\", \"h_geocode\", \"w_tr_geocode\", \"h_tr_geocode\", \"S000\"]]\n",
    "dc_flows = (\n",
    "    dc_flows.groupby([\"w_tr_geocode\", \"h_tr_geocode\"])[\"S000\"].sum().reset_index()\n",
    ")\n",
    "\n",
    "dc_flow_graph = Graph.from_adjacency(\n",
    "    adjacency=dc_flows,\n",
    "    focal_col=\"h_tr_geocode\",\n",
    "    neighbor_col=\"w_tr_geocode\",\n",
    "    weight_col=\"S000\",\n",
    ")\n",
    "\n",
    "dc = dc.set_index(\"geoid\")\n",
    "\n",
    "# for our dataset we want the full dense matrix\n",
    "dc_interaction = pd.Series(\n",
    "    dc_flow_graph.sparse.toarray().reshape(-1),\n",
    "    index=pd.MultiIndex.from_product(\n",
    "        [dc_flow_graph.unique_ids, dc_flow_graph.unique_ids.rename(\"neighbor\")]\n",
    "    ),\n",
    ").rename(\"weight\")\n",
    "\n",
    "dc_interaction = dc_interaction.reset_index()\n",
    "\n",
    "# first merge origin attributes\n",
    "dc_interaction = dc_interaction.merge(\n",
    "    dc.drop(columns=[\"geometry\"]), left_on=\"focal\", right_index=True, how=\"left\"\n",
    ")\n",
    "\n",
    "# now merge destination attributes\n",
    "dc_interaction = dc_interaction.merge(\n",
    "    dc.drop(columns=[\"geometry\"]),\n",
    "    left_on=\"neighbor\",\n",
    "    right_index=True,\n",
    "    how=\"left\",\n",
    "    suffixes=[\"_origin\", \"_destination\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Confluence of `Graphs`\n",
    "\n",
    "What's \"near\" to a *flow*?\n",
    "\n",
    "### Distance Graph\n",
    "\n",
    "As with the conventional models in the previous section, we need the distance between each OD pair as a variable for our model. Again we keep only tracts in the dataframe in our flow graph (origins), then get distance between observations with no decay using a `Graph`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dc = dc.to_crs(dc.estimate_utm_crs())\n",
    "\n",
    "dc = dc[dc.index.isin(dc_flow_graph.unique_ids)]\n",
    "\n",
    "dc_dist = Graph.build_distance_band(\n",
    "    dc.set_geometry(dc.centroid), threshold=1e20, binary=False, alpha=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dc_dist.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dc_dist.adjacency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subset the distance graph by the travel graph (remove destinations we dont need)\n",
    "# but this resets weights to 1\n",
    "dc_dist_adj = dc_dist.intersection(dc_flow_graph).adjacency\n",
    "\n",
    "# update with the old values\n",
    "dc_dist_adj.update(dc_dist.adjacency)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now create our dataset using the dense matrix 'melted' down into a vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dc_interaction[\"distance\"] = dc_dist.sparse.toarray().reshape(-1)\n",
    "\n",
    "dc_interaction['weight'] = dc_interaction['weight'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contiguity Graph\n",
    "\n",
    "Now we need to relate the origin and destination observations together. To keep\n",
    "things simple, we consider the standard contiguity graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contg = Graph.build_contiguity(dc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imagine you had a flow that moved from north to south like the map below. The\n",
    "'neighborhood' of this flow might be the tracts surrounding the origin in the\n",
    "north, those surrounding the destination in the south, or a combination thereof."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "focus_tracts = [\"11001007703\", \"11001001804\"]\n",
    "\n",
    "contg.explore(dc.centroid)\n",
    "\n",
    "m = dc.explore(tiles=\"CartoDB Positron\", tooltip=[\"geoid\"])\n",
    "contg.explore(\n",
    "    dc,\n",
    "    m=m,\n",
    "    focal=focus_tracts,\n",
    "    edge_kws=dict(color=\"red\"),\n",
    "    node_kws=dict(style_kwds=dict(radius=4, color=\"yellow\")),\n",
    ")\n",
    "l = gpd.GeoDataFrame(geometry=[LineString(dc.loc[focus_tracts].geometry.centroid.get_coordinates()[['x','y']].values)], crs=dc.crs)\n",
    "l.explore(m=m, color='red', style_kwds={'weight':6})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spatial Graphs for Origin-Destination Flows\n",
    "\n",
    "the `contg` Graph encodes flows as neighbors if the origin tracts share a\n",
    "border. But we need to multiply that graph to get it into the correct dimensions\n",
    "to match our flow data. Following @lesage2008SpatialEconometric and\n",
    "@fischer2008ModelingSpatial we do this via a\n",
    "[*Kronecker* product](https://en.wikipedia.org/wiki/Kronecker_product) between\n",
    "our flow and contiguity graphs to create the graph ($W$) used in the model.\n",
    "\n",
    "![Kronecker Product](../img/kron.png)\n",
    "\n",
    "$G_{flow} \\otimes G_{cont}$, where $\\otimes$ is the Kronecker product of the\n",
    "flow graph and contiguity graphs that defines connectivity between origin and\n",
    "destination observations.\n",
    "\n",
    "In this case observations are neighbors if:\n",
    "\n",
    "- there is a flow between o and d\n",
    "- if o_i shares a border with o_j\n",
    "- three distinct possibilities depending on how the flow graph is ordered\n",
    "  - origin-centric weights\n",
    "  - destination-centric weights\n",
    "  - OD-centric weights (union or sum of oW and dW)\n",
    "\n",
    "To do this in code, we use `scipy` to take the Kronecker product of the two\n",
    "`Graph`s, then re-instantiate a new one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kg = Graph.from_sparse(scipy.sparse.kron(dc_flow_graph.transform(\"b\").sparse, contg.sparse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "our new graph now as the same length as our observation vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kg.n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dc_interaction.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kg.pct_nonzero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contg.pct_nonzero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dc_flow_graph.pct_nonzero"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "since our original `Graph` has the origin as its focal observation, this is an origin-centric ODW ($^oW$), so to get the destination-centric weights\n",
    "($^dW$) you'd do the transpose of the OD matrix (flow graph) first\n",
    "[@lesage2008SpatialEconometric]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kgd = Graph.from_sparse(scipy.sparse.kron(dc_flow_graph.transform(\"b\").sparse.transpose(), contg.sparse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kgd.pct_nonzero"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "row-standardize both origin and destination versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kg = kg.transform('r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kgd = kgd.transform('r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`spreg` will only treat the Graph as a matrix, so the ordering of the sparse\n",
    "representation is all that matters, not the indices/labels; i.e. the Graph has\n",
    "the correct shape and order even though the indices of the Graph are different\n",
    "than those of the observations\n",
    "\n",
    "## Main Model Specification\n",
    "\n",
    "> \"Note in some cases yij = 0, indicating the absence of flows from i to j. This\n",
    "> leads to the so-called zero problem, since the logarithm then is undefined.\n",
    "> There are several pragmatic solutions to this problem, with adding a small\n",
    "> constant to the zero elements of [yij ] being widely used. Here we added\n",
    "> 0.08.\" [@fischer2008ModelingSpatial]\n",
    "\n",
    "that gives our $y$ variable a distribution like this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dc_interaction.weight.replace(0,0.08).apply(np.log).hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another common transformation is to add 1 to every observation and take the log\n",
    "of *that*, i.e. take $log(x+1)$ (this is setting $\\delta=1$ in\n",
    "@eq-interaction-log-linear)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dc_interaction.weight.apply(np.log1p).hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we specify a log-linear model using `formulaic` to generate our $y$ and $X$ matrices, then pass these to different kinds of spatial econometric models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "form = \"np.log1p(weight) ~ 1+ np.log1p(n_total_pop_origin) + np.log1p(median_household_income_origin) + np.log1p(p_nonhisp_black_persons_origin) + np.log1p(n_total_pop_destination) + np.log1p(median_household_income_destination) + np.log1p(p_nonhisp_black_persons_destination) + np.log1p(distance)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = Formula(form)\n",
    "\n",
    "# mean-impute missing values for convenience\n",
    "y, x = f.get_model_matrix(\n",
    "    dc_interaction.fillna(dc_interaction.mean(numeric_only=True))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spatial Lag\n",
    "\n",
    "### Origin centric weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flow_lag = GM_Lag(y=y, x=x, w=kg, robust='white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| column: page\n",
    "print(flow_lag.summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flow_lag.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(flow_lag.u.flatten()).hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Destination-centric weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dest_flow_lag = GM_Lag(y=y, x=x,  w=kgd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| column: page\n",
    "print(dest_flow_lag.summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dest_flow_lag.output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OD-centric weights\n",
    "\n",
    "one \"OD-graph\" could be the union of the two; a flow is 'neighbors' with another flow if it is contiguous with *either* origin or destination points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kg_od = kg.transform('b').union(kgd.transform('b'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kg_od = kg_od.transform('r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kg_od.pct_nonzero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "od_flow_lag = GM_Lag(y=y, x=x, w=kg_od)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| column: page\n",
    "\n",
    "print(od_flow_lag.summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "od_flow_lag.output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead, we could take the sum of the two graphs, in which case you are\n",
    "neighbors when contiguous with *either* origin or destination points (same\n",
    "cardinalities as above), but the strength of the weight is 2x if you neighbor\n",
    "*both* origin and destination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kg_od = Graph.from_sparse(kg.transform('b').sparse + kgd.transform('b').sparse)\n",
    "kg_od = kg_od.transform('r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| column: page\n",
    "\n",
    "print(od_flow_lag.summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "od_flow_lag.output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spatial Error\n",
    "\n",
    "the error models take a really long time to estimate\n",
    "\n",
    "### Origin-Centric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flow_error_origin = GMM_Error(y=y, x=x, w=kg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| column: page\n",
    "\n",
    "print(flow_error_origin.summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flow_error_origin.output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Destination-centric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flow_error_dest = GMM_Error(y=y, x=x, w=kgd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| column: page\n",
    "\n",
    "print(flow_error_dest.summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flow_error_dest.output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OD-Centric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flow_error_od = GMM_Error(y=y, x=x, w=kg_od)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| column: page\n",
    "\n",
    "print(flow_error_od.summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flow_error_od.output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "::: callout-note :::\n",
    "\n",
    "As an alternative to the spatial econometric specifications illustrated above,\n",
    "@liao2025DataDrivenApproach recently described a different model that\n",
    "incorporates the \"intervening opportunities\" and \"competing destinations\"\n",
    "frameworks discussed in the spatial interaction literature by incorporating two\n",
    "additional terms $A_i$ and $A_j$ which represent accessibility measures at the\n",
    "origin and destination locations, respectively. In spatial econometric parlance,\n",
    "this approach is equivalent to a spatial lag of X (SLX) model with terms that\n",
    "include both origin-centric and destination-centric lagged X variables\n",
    "[@lesage2016SpatialRegressionBased].\n",
    "\n",
    ":::\n",
    "\n",
    "\n",
    "## References\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:nersa25]",
   "language": "python",
   "name": "conda-env-nersa25-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
